# =====================================================
# ğŸš— Otomotiv RAG Sistemi â€” FAISS + Gemini (CSV versiyonu)
# =====================================================
# Bu proje, otomotiv sektÃ¶rÃ¼ iÃ§in bir Retrieval-Augmented Generation (RAG) sistemini gÃ¶stermektedir.
# Sistem, etkili benzerlik aramasÄ± iÃ§in FAISS'i ve alÄ±nan bilgilere dayanarak yanÄ±tlar oluÅŸturmak iÃ§in Gemini modelini kullanÄ±r.
# Sistem, veri kaynaÄŸÄ± olarak bir CSV dosyasÄ± kullanmaktadÄ±r.
# ğŸ“¦ Gerekli kÃ¼tÃ¼phaneler
# KÃ¼tÃ¼phaneler not defterinde zaten yÃ¼klÃ¼, uygulama dosyasÄ±nda tekrar yÃ¼klemeye gerek yok

import gradio as gr
import pandas as pd
import numpy as np
import faiss
import google.generativeai as genai
import os
from dotenv import load_dotenv
from tqdm import tqdm

file_path = os.path.join(os.getcwd(), "Automobile.csv")  # GeÃ§erli Ã§alÄ±ÅŸma dizininde ("current working directory") bulunan "Automobile.csv" dosyasÄ±nÄ±n tam dosya yolunu oluÅŸturur.
df = pd.read_csv(file_path)  # Belirtilen dosya yolundaki CSV dosyasÄ±nÄ± okur ve bir pandas DataFrame'e yÃ¼kler.
gerekli_sutunlar = ["name", "horsepower", "weight", "model_year", "origin"]  # Veri setinde analiz veya iÅŸlem iÃ§in gerekli olan sÃ¼tunlarÄ± tanÄ±mlar.
df = df.dropna(subset=gerekli_sutunlar)  # Belirtilen sÃ¼tunlarda eksik (NaN) deÄŸer iÃ§eren satÄ±rlarÄ± veri setinden kaldÄ±rÄ±r.

# =====================================================
# 2ï¸âƒ£ Veriyi metin haline getir
# =====================================================
# DataFrame'in her satÄ±rÄ±nÄ±, aracÄ± aÃ§Ä±klayan bir metin dizesine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n.
# Bu metin, RAG sistemi iÃ§in embedding oluÅŸturmak iÃ§in kullanÄ±lacaktÄ±r.

def row_to_text(row):
    return (
        f"AraÃ§ adÄ±: {row['name']}, Beygir GÃ¼cÃ¼: {row['horsepower']} HP, "
        f"AÄŸÄ±rlÄ±k: {row['weight']} kg, Ãœretim YÄ±lÄ±: {row['model_year']}, "
        f"Ãœlke: {row['origin']}."
    )
documents = [row_to_text(row) for _, row in df.iterrows()]

# =====================================================
# 3ï¸âƒ£ Gemini API yapÄ±landÄ±rmasÄ±
# =====================================================

load_dotenv() # .env dosyasÄ±nÄ± yÃ¼kler ve deÄŸiÅŸkenleri os.environ'a ekler
genai.configure(api_key=os.environ.get("GOOGLE_API_KEY"))

# =====================================================
# 4ï¸âƒ£ Embedding oluÅŸtur (Gemini Embeddings)
# =====================================================

embed_model = "text-embedding-004"  # KullanÄ±lacak embedding (gÃ¶mÃ¼ntÃ¼) modelinin adÄ±nÄ± belirler.
embeddings = []  # OluÅŸturulacak embedding'leri saklamak iÃ§in boÅŸ bir liste oluÅŸturur.
for doc in tqdm(documents, desc="Embedding oluÅŸturuluyor"):  # documents listesindeki her belge iÃ§in dÃ¶ngÃ¼ oluÅŸturur ve ilerlemeyi gÃ¶sterir.
    try:
        result = genai.embed_content(model=embed_model, content=doc)  # Belgeyi seÃ§ilen model ile vektÃ¶r (embedding) haline getirir.
        embeddings.append(result["embedding"])  # OluÅŸan embedding'i listeye ekler.
    except Exception as e:
        tqdm(f"hata: {e}")  # EÄŸer bir hata oluÅŸursa, hatayÄ± ekrana yazdÄ±rÄ±r.
        embeddings.append(np.zeros(768))  # Hata durumunda 768 boyutunda sÄ±fÄ±r vektÃ¶rÃ¼ ekler.
embeddings = np.array(embeddings).astype("float32")  # TÃ¼m embedding listesini numpy array'e Ã§evirir ve veri tipini float32 yapar.

# =====================================================
# 5ï¸âƒ£ FAISS Index oluÅŸtur
# =====================================================

dimension = len(embeddings[0]) if len(embeddings) > 0 else 0  # Embeddinglerin boyutunu alÄ±r; liste boÅŸsa 0 olarak ayarlar.
index = None  # FAISS index deÄŸiÅŸkenini baÅŸlatÄ±r (ÅŸimdilik None).
if dimension == 0:
    raise ValueError("Embedding oluÅŸturulamadÄ±.")  # EÄŸer embedding yoksa hata verir.
index = faiss.IndexFlatL2(dimension)  # FAISS kÃ¼tÃ¼phanesi ile L2 (Euclidean) mesafeye gÃ¶re bir dÃ¼z (flat) index oluÅŸturur.
index.add(embeddings)  # OluÅŸturulan embedding'leri FAISS index'e ekler.

# =====================================================
# 6ï¸âƒ£ RAG sistemi
# =====================================================
# Gemini modeli iÃ§in prompt ÅŸablonunu tanÄ±mlayÄ±n.
# Bu ÅŸablon, modele bir otomotiv uzmanÄ± gibi davranmasÄ±nÄ± ve saÄŸlanan baÄŸlamÄ±
# kullanarak kullanÄ±cÄ±nÄ±n sorusuna yanÄ±t vermesini talimat verir.

prompt_template = """
Sen otomotiv sektÃ¶rÃ¼nde uzman bir yapay zekÃ¢ asistanÄ±sÄ±n.

KullanÄ±cÄ±nÄ±n sorusuna aÅŸaÄŸÄ±daki baÄŸlamÄ± (context) kullanarak:
-Otomobil gazetecisi gibi
-DoÄŸru
-AnlaÅŸÄ±lÄ±r
bir yanÄ±t ver.

EÄŸer baÄŸlamda yeterli bilgi yoksa "Bu konuda elimde yeterli bilgi yok." de.

BaÄŸlam:
{context}

Soru:
{question}

YanÄ±t:
"""

def retrieve_context(query, top_k=3):
    """
    KullanÄ±cÄ±nÄ±n sorgusuna en uygun baÄŸlamlarÄ± dÃ¶ndÃ¼rÃ¼r.

    Args:
        query (str): KullanÄ±cÄ±nÄ±n sorusu veya sorgusu.
        top_k (int): KaÃ§ adet en benzer baÄŸlamÄ±n dÃ¶ndÃ¼rÃ¼leceÄŸi.

    Returns:
        list: En benzer belgelerin listesi.
    """
    if not isinstance(embeddings, np.ndarray) or embeddings.size == 0 or index is None:
        print("âš ï¸ Embeddingler veya FAISS indexi mevcut deÄŸil.") 
        return []

    try:
        # Sorgu iÃ§in bir embedding oluÅŸturun
        q_embed = genai.embed_content(model=embed_model, content=query)["embedding"]
        q_embed = np.array([q_embed]).astype("float32")

        # En benzer belgeleri FAISS indexinde arayÄ±n
        distances, indices = index.search(q_embed, top_k)

        # En iyi 'top_k' benzer belgelerin iÃ§eriÄŸini alÄ±n
        results = [documents[i] for i in indices[0]]

        return results

    except Exception as e:
        print(f"Sorgu iÃ§in baÄŸlam alÄ±nÄ±rken hata oluÅŸtu: {query[:50]}... Hata: {e}") 
        return []


# KullanÄ±cÄ±nÄ±n sorusuna, alÄ±nan baÄŸlam ve Gemini modeli ile yanÄ±t oluÅŸturur
def generate_answer(question):
    # Sorguya en uygun baÄŸlam belgelerini alÄ±n
    context_docs = retrieve_context(question)

    # EÄŸer baÄŸlam bulunamazsa, kullanÄ±cÄ±ya bunu belirten mesaj dÃ¶ndÃ¼r
    if not context_docs:
        return "Bu konuda elimde yeterli bilgi yok."

    # BaÄŸlam belgelerini tek bir metin hÃ¢line getirin
    context = "\n".join(context_docs)

    # Prompt'u baÄŸlam ve soruya gÃ¶re biÃ§imlendir
    prompt = prompt_template.format(context=context, question=question)

    # YanÄ±t Ã¼retmek iÃ§in Gemini modelini seÃ§in
    model = genai.GenerativeModel("gemini-2.5-flash")  # Gerekiyorsa baÅŸka bir desteklenen modelle deÄŸiÅŸtirin

    try:
        # Modeli kullanarak yanÄ±tÄ± oluÅŸtur
        response = model.generate_content(prompt)
        return response.text

    except Exception as e:
        # Hata durumunda kullanÄ±cÄ±ya bilgi ver ve logla
        print(f"Soru iÃ§in yanÄ±t oluÅŸturulurken hata oluÅŸtu: {question[:50]}... Hata: {e}")
        return "YanÄ±t oluÅŸturulurken bir hata oluÅŸtu."


# =====================================================
# 7ï¸âƒ£ Gradio UygulamasÄ±
# =====================================================
# RAG sistemi ile etkileÅŸim kurmak iÃ§in bir Gradio arayÃ¼zÃ¼ oluÅŸturun.
# ArayÃ¼z, bir metin giriÅŸi (kullanÄ±cÄ±nÄ±n sorusu) alÄ±r ve bir metin Ã§Ä±ktÄ±sÄ± (oluÅŸturulan yanÄ±t) saÄŸlar.

iface = gr.Interface(
    fn=generate_answer,
    inputs=gr.Textbox(label="Arabalar HakkÄ±nda Bir Soru Sorun"),
    outputs=gr.Textbox(label="YanÄ±t: ", lines=10), # lines parametresini ekledik ve 10 yaptÄ±k
    title= "OTOMOTÄ°V RAG SÄ°STEMÄ°",
    allow_flagging="never"
)
iface.launch(debug=True, share=True)